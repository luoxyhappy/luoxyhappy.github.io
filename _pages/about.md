---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üë®‚Äçüéì About me

I am currently a 1st-Year Master student at [Tsinghua University](https://www.tsinghua.edu.cn/en/) <img src='./images/thu.png' style='width: 2em;'>. I got B.Eng. degree in Computer Science (Yingcai Honor School) at [University of Electronic Science and Technology of China](https://www.uestc.edu.cn/) <img src='./images/uestc.png' style='width: 2em;'>. 

Currently, I‚Äôm interested in AIGC, specializing in ‚ÄãVideo Generation.‚Äã
 

<br>


%# üíª Experience

%08/2024 ~ 03/2025, I was a research intern at the [IDEA](https://www.idea.edu.cn/).

%<br>

# üìù Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/CanonSwap.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://arxiv.org/abs/2407.06984" style="font-size: 22px; color: #483D8B; text-decoration: none">**CanonSwap: High-Fidelity and Consistent Video Face Swapping via Canonical Space Modulation**</a><br>
<span style="font-size: 18px;">**Xiangyang Luo** , Ye Zhu‚Ä†, Yunfei Liu, Lijian Lin, Cong Wan, Zijian Cai, Shao-Lun Huang‚Ä†, Yu Li</span><br>
<span style="font-size: 18px;">[**Page**](https://luoxyhappy.github.io/CanonSwap/)  </span>

<span style="font-size: 18px;">-  CanonSwap decouples motion information from appearance to enable high-fidelity and consistent video face swapping.</span>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2025</div><img src='images/OIA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://www.arxiv.org/pdf/2503.23353" style="font-size: 22px; color: #483D8B; text-decoration: none">**Object Isolated Attention for Consistent Story Visualization**</a><br>
<span style="font-size: 18px;">**Xiangyang Luo**, Junhao Cheng, Yifan Xie, Xin Zhang, Tao Feng, Zhou Liu, Fei Ma‚Ä†, Fei Yu</span><br>
<span style="font-size: 18px;">[**Paper**](https://www.arxiv.org/pdf/2503.23353)</span>

<span style="font-size: 18px;">- We proposes a training-free method that uses isolated attention mechanisms to maintain character consistency and prevent feature confusion in story visualization.</span>

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2024</div><img src='images/CodeSwap.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

<a href="https://dl.acm.org/doi/10.1145/3664647.3681120" style="font-size: 22px; color: #483D8B; text-decoration: none">**GUAVA: Generalizable Upper Body 3D Gaussian Avatar**</a><br>
<span style="font-size: 18px;"> **Xiangyang Luo**, Xin Zhang, Yifan Xie, Xinyi Tong, Weijiang Yu, Heng Chang, Fei Ma‚Ä†, Fei Ricahrd Yu</span><br>
<span style="font-size: 18px;">[**Paper**](https://dl.acm.org/doi/10.1145/3664647.3681120)</span>

<span style="font-size: 18px;">-  CodeSwap achieves high-fidelity face swapping by symmetrically manipulating codes within a pre-trained, high-quality facial codebook. </span>

</div>
</div>

%# üèÜ Honors and Awards

%- National First Prize (0.7%), [CUMCM: China Undergraduate Mathematical Contest in Modeling](https://www.mcm.edu.cn/html_cn/node/5d988b4e510d9dc78168e258dc76a48f.html), 2021.

